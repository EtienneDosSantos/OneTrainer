# Validation Loss: Monitoring Training Progress with FID Scores

Validation loss, implemented as FID (Fr√©chet Inception Distance) scores, is a valuable metric for monitoring the training progress of your model. It complements training loss and smooth loss by providing insights into the model's performance on unseen data.

## How it Works

- FID scores are calculated at regular intervals (currently only supported after each epoch) using a validation image set.
- The validation set is a portion[^1] of the training image set that is not used for training the LoRA model.
- FID scores measure the similarity between the validation images and the images generated by the model after each epoch.

## Interpreting Validation Loss

- Lower FID scores signify greater similarity between the generated images and the validation images, indicating that the model's capability of generalizing to unseen data is improving.
- Conversely, if the validation loss (FID score) continues to rise consistently, it suggests that the model may be overfitting[^2] to the training images and not adapting well to unseen data.

## Benefits of Monitoring Validation Loss

Validation loss provides insights into:

- When to stop training to prevent overfitting
- Which hyperparameters to tune for optimal performance
- How well the model generalizes to unseen data

By monitoring validation loss, you can make informed decisions to improve your model's performance and ensure it learns meaningful representations of the data.

## Implementation Considerations

To utilize validation loss effectively:

1. **Validation Image Set:** Create a separate set of validation images representative of the data distribution but not used during training.
2. **Concept Configuration:** In your `concepts.json`[^3] file, define a concept named "validation_images" with the path to your validation image set. Ensure that this concept is disabled by setting `"disabled": true`, otherwise it will be included as part of the training image set.
3. **Epochs Folder:** FID scores and generated images for each epoch are stored in a hidden "epochs" folder within your workspace directory.
4. **FID Score Calculation:** FID scores are calculated after each epoch and logged to TensorBoard for visualization.
5. **Customization:** You can modify the code to calculate FID scores at different intervals if needed.

[^1]: Allocating 15% of your dataset to the validation set can be a good middle ground.
[^2]: Overfitting means the model has learned the representations of the training images too well, which is detrimental to its ability to generalize to new, unseen data (e.g., the validation images).
[^3]: Modify the `concepts.json` file directly or through the concepts tab in the UI, which automatically updates the file.

